# Mertalizer: Music Structure Recognition

A comprehensive system for detecting musical structure boundaries and assigning section labels (intro/verse/pre-chorus/chorus/bridge/solo/outro/other) using music-native SSL encoders.

## üéµ Features

- **Primary Model**: MERT v1 95M SSL encoder with a TCN boundary detector and linear label head
- **Optional Variants**: Swap in w2v-BERT-2.0 encoder or a transformer boundary head via config overrides
- **Datasets**: Harmonix Set, SALAMI, Beatles/Isophonics, SPAM, CCMUSIC
- **Outputs**: Trained checkpoints, CLI & REST inference, evaluation reports
- **Web Dashboard**: Interactive audio upload and visualization interface
- **Rust Integration**: High-performance web server and audio processing

## üèóÔ∏è Project Structure

```
mertalizer/
‚îú‚îÄ‚îÄ src/                    # Python ML components
‚îÇ   ‚îú‚îÄ‚îÄ data/              # Data processing and ingestion
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ontology.py    # Label mapping system
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ fetch_datasets.py  # Dataset downloader
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ingestion.py   # Data normalization
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ preprocessing.py   # Audio preprocessing
‚îÇ   ‚îú‚îÄ‚îÄ modeling/          # Model architectures
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ system.py      # Two-head architecture
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ssm_novelty.py # Classic baseline
‚îÇ   ‚îú‚îÄ‚îÄ training/          # Training scripts
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ train.py       # LightningModule training
‚îÇ   ‚îú‚îÄ‚îÄ evaluation/        # Metrics and evaluation
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ metrics.py     # Boundary & label metrics
‚îÇ   ‚îú‚îÄ‚îÄ inference/         # CLI and REST API
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ cli.py         # Command-line interface
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ api.py         # FastAPI REST server
‚îÇ   ‚îî‚îÄ‚îÄ export/            # ONNX export
‚îÇ       ‚îî‚îÄ‚îÄ onnx.py        # Model export utilities
‚îú‚îÄ‚îÄ rust/                  # Rust components
‚îÇ   ‚îú‚îÄ‚îÄ web/               # Web server
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ main.rs       # Axum web server
‚îÇ   ‚îî‚îÄ‚îÄ Cargo.toml         # Rust dependencies
‚îú‚îÄ‚îÄ configs/               # Model configurations
‚îÇ   ‚îú‚îÄ‚îÄ mert_95m.yaml     # MERT configuration
‚îÇ   ‚îî‚îÄ‚îÄ w2v_baseline.yaml # w2v-BERT configuration
‚îú‚îÄ‚îÄ web_dashboard/         # Frontend dashboard
‚îÇ   ‚îî‚îÄ‚îÄ templates/         # HTML templates
‚îú‚îÄ‚îÄ data/                  # Dataset storage
‚îú‚îÄ‚îÄ models/                # Trained checkpoints
‚îú‚îÄ‚îÄ demo.sh                # End-to-end capability walkthrough
‚îú‚îÄ‚îÄ example.sh             # Sample pipeline runner
‚îú‚îÄ‚îÄ run_server.sh          # Launch Python API + Rust web UI
‚îî‚îÄ‚îÄ setup.sh               # Environment bootstrapper
```

## üöÄ Quick Start

### Option 1: Complete Example Pipeline
```bash
# See all features in action
./demo.sh

# Run the complete example pipeline
./example.sh
```

### Option 2: Manual Setup
```bash
# 1. Setup environment
./setup.sh

# 2. Download datasets
python src/data/fetch_datasets.py --all

# 3. Process data
python src/data/ingestion.py --all

# 4. Extract embeddings (repeat for each dataset JSONL)
python src/data/preprocessing.py --annotations data/processed/ccmusic.jsonl --dataset-name ccmusic

# 5. Train model on precomputed embeddings
python src/training/train.py --config configs/mert_95m.yaml

# 6. Start web servers
./run_server.sh
```

> The embedding step looks up the `dataset` field in each JSON line and expects artifacts under `data/processed/embeddings/<dataset>/<track_id>.npz`. Repeat the command above for every dataset JSONL you ingested (e.g. `harmonix.jsonl`, `salami.jsonl`) and adjust `--dataset-name` accordingly.

## üîß Environment Variables

Create a `.env` file with:
```bash
# Hugging Face token for dataset access
HF_TOKEN=your_hf_token_here

# Weights & Biases API key (optional)
WANDB_KEY=your_wandb_key_here

# Model paths
MODEL_PATH=models/checkpoints/final_model.ckpt
PYTHON_API_URL=http://localhost:8000

# Server settings
PORT=3000
```

## üìä Usage

### Web Dashboard
- **URL**: http://localhost:3000
- Upload audio files and visualize structure analysis
- Interactive waveform with segment boundaries
- Real-time structure charts and statistics

### CLI Inference
```bash
# Single file
python src/inference/cli.py audio.wav --model models/checkpoints/final_model.ckpt

# Batch processing
python src/inference/cli.py audio_dir/ --model models/checkpoints/final_model.ckpt --batch

# Export results
python src/inference/cli.py audio.wav --model models/checkpoints/final_model.ckpt --output results.json
```

### REST API
```bash
# Health check
curl http://localhost:8000/health

# Predict structure
curl -X POST -F "audio_file=@audio.wav" http://localhost:8000/predict

# API documentation
open http://localhost:8000/docs
```

### ONNX Export
```bash
# Export trained model to ONNX
python src/export/onnx.py --checkpoint models/checkpoints/final_model.ckpt --output models/model.onnx

# Test ONNX model
python src/export/onnx.py --checkpoint models/checkpoints/final_model.ckpt --output models/model.onnx --test
```

## üéØ Model Architecture

### Two-Head Architecture
- **Encoder**: Frozen/fine-tunable SSL encoder (MERT 95M by default, w2v-BERT optional)
- **Boundary Head**: TCN detector (default) with configurable transformer alternative
- **Label Head**: Linear classifier predicting canonical segment classes
- **Loss**: Binary cross-entropy with optional focal term for boundaries; cross-entropy for labels

### Classic Baseline
- **Self-Similarity Matrix**: Cosine similarity between embeddings
- **Novelty Detection**: Checkerboard kernel convolution
- **Peak Detection**: Threshold-based boundary detection
- **Label Assignment**: Majority vote or heuristic rules

## üìà Evaluation Metrics

- **Boundary Detection**: F@0.5s, F@3.0s, Hit Rate
- **Label Classification**: Accuracy, Precision, Recall, F1
- **Cross-Dataset**: Generalization across different datasets
- **Error Analysis**: Confusion matrices and case studies

## üî¨ Datasets

| Dataset | Source | Annotations | Audio |
|---------|--------|-------------|-------|
| Harmonix Set | Hugging Face | Structure + Beats | Provided |
| SALAMI | GitHub | Hierarchical | External IDs |
| Beatles/Isophonics | Hugging Face | Structure + Chords | External |
| SPAM | GitHub | Multi-annotator | External |
| CCMUSIC | Hugging Face | Chinese Pop | External |

## üõ†Ô∏è Development

### Adding New Datasets
1. Update `src/data/fetch_datasets.py` with dataset configuration
2. Implement parser in `src/data/ingestion.py`
3. Add label mappings in `src/data/ontology.py`

### Custom Models
1. Create new model class in `src/modeling/`
2. Update `src/training/train.py` to support new architecture
3. Add configuration in `configs/`

### Web Dashboard Features
1. Modify `web_dashboard/templates/index.html`
2. Update Rust web server in `rust/web/main.rs`
3. Add new API endpoints in `src/inference/api.py`

## üìù Output Format

```json
{
  "track_id": "example_track",
  "sr": 22050,
  "duration": 180.5,
  "boundaries": [0.0, 12.5, 25.0, 37.5, 50.0],
  "labels": ["INTRO", "VERSE", "CHORUS", "VERSE", "OUTRO"],
  "segments": [
    {"start": 0.0, "end": 12.5, "label": "INTRO"},
    {"start": 12.5, "end": 25.0, "label": "VERSE"},
    {"start": 25.0, "end": 37.5, "label": "CHORUS"},
    {"start": 37.5, "end": 50.0, "label": "VERSE"},
    {"start": 50.0, "end": 180.5, "label": "OUTRO"}
  ],
  "version": "mert-95m-tcn@2025-01-24"
}
```

## ü§ù Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Add tests if applicable
5. Submit a pull request

## üìÑ License

MIT License - Educational/Research Use

## üôè Acknowledgments

- MERT team for the SSL encoder
- Hugging Face for dataset hosting
- PyTorch Lightning for training framework
- Axum for Rust web framework
